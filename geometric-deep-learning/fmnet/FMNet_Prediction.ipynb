{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Functional Maps\n",
    "----\n",
    "\n",
    "Predict correspondences within similar 3D shapes by using *geometric deep learning* (deep learning for non-Euclidean space). This was published in ICCV 2017 by Litany *et al*., [Deep Functional Maps: Structured Prediction for Dense Shape Correspondence](http://openaccess.thecvf.com/content_iccv_2017/html/Litany_Deep_Functional_Maps_ICCV_2017_paper.html).\n",
    "\n",
    "![The network architecture](https://raw.githubusercontent.com/orlitany/DeepFunctionalMaps/master/fmnet.png)\n",
    "\n",
    "This is my attempt trying to understand the paper by reproducing it in this notebook from the source code provided by the first author: [@orlitany](https://github.com/orlitany/DeepFunctionalMaps)\n",
    "\n",
    "This notebook shows only the prediction process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import time\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the input pair data\n",
    "\n",
    "Load the pair of data. The data is 3D mesh objects which contains values from SHOT descriptor method. These descriptors have been pre-calculated.\n",
    "\n",
    "The pair is shown below. Left: source. Right: target.\n",
    "\n",
    "![Test Pair](./images/test_pair.png)\n",
    "\n",
    "You need to download the data from the link given in [@orlitany](https://github.com/orlitany/DeepFunctionalMaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'model_S', 'model_evecs', 'model_evecs_trans', 'model_shot', 'shot_params'])\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'model_S', 'model_evecs', 'model_evecs_trans', 'model_shot', 'shot_params'])\n"
     ]
    }
   ],
   "source": [
    "# load the pair of data\n",
    "source_file = r'./files/tr_reg_080.mat'\n",
    "target_file = r'./files/tr_reg_081.mat'\n",
    "\n",
    "source_data = sio.loadmat(source_file)\n",
    "target_data = sio.loadmat(target_file)\n",
    "\n",
    "print(source_data.keys())\n",
    "print(target_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't know exactly the meaning of each field in the data, but this is what the authors coded to prepare the input data\n",
    "# What I can figure out is that part == source and model == target\n",
    "\n",
    "input_data = {}\n",
    "input_data.update(source_data)\n",
    "\n",
    "input_data['part_evecs'] = input_data['model_evecs']\n",
    "input_data.pop('model_evecs')\n",
    "\n",
    "input_data['part_evecs_trans'] = input_data['model_evecs_trans']\n",
    "input_data.pop('model_evecs_trans')\n",
    "\n",
    "input_data['part_shot'] = input_data['model_shot']\n",
    "input_data.pop('model_shot')\n",
    "\n",
    "input_data.update(target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the network model\n",
    "\n",
    "The trained model is saved in `log/train_inter_k_flag/model.ckpt-1270` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./files/log/train_inter_k_flag/model.ckpt-1270\n"
     ]
    }
   ],
   "source": [
    "log_dir = './files/log/train_inter_k_flag'\n",
    "meta_file = os.path.join(log_dir, 'model.ckpt-1270.meta')\n",
    "\n",
    "# read the stored graph\n",
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph(meta_file)\n",
    "saver.restore(sess, tf.train.latest_checkpoint(log_dir))\n",
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve placeholder variable names at the input layer, used when we feed the network\n",
    "part_shot = graph.get_tensor_by_name('part_shot:0')\n",
    "model_shot = graph.get_tensor_by_name('model_shot:0')\n",
    "dist_map = graph.get_tensor_by_name('dist_map:0')\n",
    "part_evecs = graph.get_tensor_by_name('part_evecs:0')\n",
    "part_evecs_trans = graph.get_tensor_by_name('part_evecs_trans:0')\n",
    "model_evecs = graph.get_tensor_by_name('model_evecs:0')\n",
    "model_evecs_trans = graph.get_tensor_by_name('model_evecs_trans:0')\n",
    "phase = graph.get_tensor_by_name('phase:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve variable names for the output\n",
    "Ct_est = graph.get_tensor_by_name('MatrixSolveLs:0')\n",
    "softCorr = graph.get_tensor_by_name('pointwise_corr_loss/soft_correspondences:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the test\n",
    "\n",
    "Create feed dictionary for the network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_evecs= 120\n",
    "\n",
    "feed_dict = {phase: True,\n",
    "             part_shot: [input_data['part_shot']],\n",
    "             model_shot: [input_data['model_shot']],\n",
    "             dist_map: [[[None]]],\n",
    "             part_evecs: [input_data['part_evecs'][:, 0:num_evecs]],\n",
    "             part_evecs_trans: [input_data['part_evecs_trans'][0:num_evecs, :]],\n",
    "             model_evecs: [input_data['model_evecs'][:, 0:num_evecs]],\n",
    "             model_evecs_trans: [input_data['model_evecs_trans'][0:num_evecs, :]]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed correspondences for pair: tr_reg_080, tr_reg_081. Took 2.5087170600891113 seconds\n"
     ]
    }
   ],
   "source": [
    "# run the test\n",
    "t = time.time()\n",
    "Ct_est_out, softCorr_out  = sess.run([Ct_est, softCorr], feed_dict=feed_dict)\n",
    "C_est_out = Ct_est_out.transpose([0, 2, 1])\n",
    "print('Computed correspondences for pair: {}, {}. Took {} seconds'.format('tr_reg_080', 'tr_reg_081', time.time() - t))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result\n",
    "out = {\n",
    "    'C_est': C_est_out,\n",
    "    'softCorr': softCorr_out\n",
    "}\n",
    "sio.savemat(r'./files/pred/test_result.mat', out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the test result\n",
    "\n",
    "Due to 3D limitation of jupyter, visualization was done in Matlab (see author's implementation). The colormap of the target (right) was taken by the maximum response of the `softCorr` indexed by the colormap of the source (left)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Test Pair Result](./images/test_pair_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# get the maximum response\n",
    "[~, matches] = max(softCorr, [], 1);\n",
    "\n",
    "# create source colormap that is unique for each vertex\n",
    "# read the tr_reg_080.off file that contains the vertices and faces \n",
    "# assume that V = Nx3 vertices and F = Nx3 triangle faces\n",
    "mins = min(V,[],1);\n",
    "maxs = max(V,[],1);\n",
    "npts = size(V,1)\n",
    "source_cmap = (V - ones(npts, 1)*mins) ./ (ones(npts, 1) * (maxs-mins))\n",
    "\n",
    "# get the indexed colormap\n",
    "target_cmap = source_cmap(matches,:);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
